// SPDX-FileCopyrightText: 2023 The Crossplane Authors <https://crossplane.io>
//
// SPDX-License-Identifier: Apache-2.0

/*
Copyright 2022 Upbound Inc.
*/

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type ArchiveInitParameters struct {

	// (Block List, Max: 1) Definition of an azure archive. (see below for nested schema)
	// Definition of an azure archive.
	AzureArchive []AzureArchiveInitParameters `json:"azureArchive,omitempty" tf:"azure_archive,omitempty"`

	// (Block List, Max: 1) Definition of a GCS archive. (see below for nested schema)
	// Definition of a GCS archive.
	GcsArchive []GcsArchiveInitParameters `json:"gcsArchive,omitempty" tf:"gcs_archive,omitempty"`

	// (Boolean) To store the tags in the archive, set the value true. If it is set to false, the tags will be dropped when the logs are sent to the archive. Defaults to false.
	// To store the tags in the archive, set the value `true`. If it is set to `false`, the tags will be dropped when the logs are sent to the archive. Defaults to `false`.
	IncludeTags *bool `json:"includeTags,omitempty" tf:"include_tags,omitempty"`

	// (String) Your archive name.
	// Your archive name.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The archive query/filter. Logs matching this query are included in the archive.
	// The archive query/filter. Logs matching this query are included in the archive.
	Query *string `json:"query,omitempty" tf:"query,omitempty"`

	// (Number) To limit the rehydration scan size for the archive, set a value in GB.
	// To limit the rehydration scan size for the archive, set a value in GB.
	RehydrationMaxScanSizeInGb *float64 `json:"rehydrationMaxScanSizeInGb,omitempty" tf:"rehydration_max_scan_size_in_gb,omitempty"`

	// (List of String) An array of tags to add to rehydrated logs from an archive.
	// An array of tags to add to rehydrated logs from an archive.
	RehydrationTags []*string `json:"rehydrationTags,omitempty" tf:"rehydration_tags,omitempty"`

	// (Block List, Max: 1) Definition of an s3 archive. (see below for nested schema)
	// Definition of an s3 archive.
	S3Archive []S3ArchiveInitParameters `json:"s3Archive,omitempty" tf:"s3_archive,omitempty"`
}

type ArchiveObservation struct {

	// (Block List, Max: 1) Definition of an azure archive. (see below for nested schema)
	// Definition of an azure archive.
	AzureArchive []AzureArchiveObservation `json:"azureArchive,omitempty" tf:"azure_archive,omitempty"`

	// (Block List, Max: 1) Definition of a GCS archive. (see below for nested schema)
	// Definition of a GCS archive.
	GcsArchive []GcsArchiveObservation `json:"gcsArchive,omitempty" tf:"gcs_archive,omitempty"`

	// (String) The ID of this resource.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// (Boolean) To store the tags in the archive, set the value true. If it is set to false, the tags will be dropped when the logs are sent to the archive. Defaults to false.
	// To store the tags in the archive, set the value `true`. If it is set to `false`, the tags will be dropped when the logs are sent to the archive. Defaults to `false`.
	IncludeTags *bool `json:"includeTags,omitempty" tf:"include_tags,omitempty"`

	// (String) Your archive name.
	// Your archive name.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The archive query/filter. Logs matching this query are included in the archive.
	// The archive query/filter. Logs matching this query are included in the archive.
	Query *string `json:"query,omitempty" tf:"query,omitempty"`

	// (Number) To limit the rehydration scan size for the archive, set a value in GB.
	// To limit the rehydration scan size for the archive, set a value in GB.
	RehydrationMaxScanSizeInGb *float64 `json:"rehydrationMaxScanSizeInGb,omitempty" tf:"rehydration_max_scan_size_in_gb,omitempty"`

	// (List of String) An array of tags to add to rehydrated logs from an archive.
	// An array of tags to add to rehydrated logs from an archive.
	RehydrationTags []*string `json:"rehydrationTags,omitempty" tf:"rehydration_tags,omitempty"`

	// (Block List, Max: 1) Definition of an s3 archive. (see below for nested schema)
	// Definition of an s3 archive.
	S3Archive []S3ArchiveObservation `json:"s3Archive,omitempty" tf:"s3_archive,omitempty"`
}

type ArchiveParameters struct {

	// (Block List, Max: 1) Definition of an azure archive. (see below for nested schema)
	// Definition of an azure archive.
	// +kubebuilder:validation:Optional
	AzureArchive []AzureArchiveParameters `json:"azureArchive,omitempty" tf:"azure_archive,omitempty"`

	// (Block List, Max: 1) Definition of a GCS archive. (see below for nested schema)
	// Definition of a GCS archive.
	// +kubebuilder:validation:Optional
	GcsArchive []GcsArchiveParameters `json:"gcsArchive,omitempty" tf:"gcs_archive,omitempty"`

	// (Boolean) To store the tags in the archive, set the value true. If it is set to false, the tags will be dropped when the logs are sent to the archive. Defaults to false.
	// To store the tags in the archive, set the value `true`. If it is set to `false`, the tags will be dropped when the logs are sent to the archive. Defaults to `false`.
	// +kubebuilder:validation:Optional
	IncludeTags *bool `json:"includeTags,omitempty" tf:"include_tags,omitempty"`

	// (String) Your archive name.
	// Your archive name.
	// +kubebuilder:validation:Optional
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (String) The archive query/filter. Logs matching this query are included in the archive.
	// The archive query/filter. Logs matching this query are included in the archive.
	// +kubebuilder:validation:Optional
	Query *string `json:"query,omitempty" tf:"query,omitempty"`

	// (Number) To limit the rehydration scan size for the archive, set a value in GB.
	// To limit the rehydration scan size for the archive, set a value in GB.
	// +kubebuilder:validation:Optional
	RehydrationMaxScanSizeInGb *float64 `json:"rehydrationMaxScanSizeInGb,omitempty" tf:"rehydration_max_scan_size_in_gb,omitempty"`

	// (List of String) An array of tags to add to rehydrated logs from an archive.
	// An array of tags to add to rehydrated logs from an archive.
	// +kubebuilder:validation:Optional
	RehydrationTags []*string `json:"rehydrationTags,omitempty" tf:"rehydration_tags,omitempty"`

	// (Block List, Max: 1) Definition of an s3 archive. (see below for nested schema)
	// Definition of an s3 archive.
	// +kubebuilder:validation:Optional
	S3Archive []S3ArchiveParameters `json:"s3Archive,omitempty" tf:"s3_archive,omitempty"`
}

type AzureArchiveInitParameters struct {

	// (String) Your client id.
	// Your client id.
	ClientID *string `json:"clientId,omitempty" tf:"client_id,omitempty"`

	// (String) The container where the archive is stored.
	// The container where the archive is stored.
	Container *string `json:"container,omitempty" tf:"container,omitempty"`

	// (String) The path where the archive is stored.
	// The path where the archive is stored.
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// (String) The associated storage account.
	// The associated storage account.
	StorageAccount *string `json:"storageAccount,omitempty" tf:"storage_account,omitempty"`

	// (String) Your tenant id.
	// Your tenant id.
	TenantID *string `json:"tenantId,omitempty" tf:"tenant_id,omitempty"`
}

type AzureArchiveObservation struct {

	// (String) Your client id.
	// Your client id.
	ClientID *string `json:"clientId,omitempty" tf:"client_id,omitempty"`

	// (String) The container where the archive is stored.
	// The container where the archive is stored.
	Container *string `json:"container,omitempty" tf:"container,omitempty"`

	// (String) The path where the archive is stored.
	// The path where the archive is stored.
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// (String) The associated storage account.
	// The associated storage account.
	StorageAccount *string `json:"storageAccount,omitempty" tf:"storage_account,omitempty"`

	// (String) Your tenant id.
	// Your tenant id.
	TenantID *string `json:"tenantId,omitempty" tf:"tenant_id,omitempty"`
}

type AzureArchiveParameters struct {

	// (String) Your client id.
	// Your client id.
	// +kubebuilder:validation:Optional
	ClientID *string `json:"clientId" tf:"client_id,omitempty"`

	// (String) The container where the archive is stored.
	// The container where the archive is stored.
	// +kubebuilder:validation:Optional
	Container *string `json:"container" tf:"container,omitempty"`

	// (String) The path where the archive is stored.
	// The path where the archive is stored.
	// +kubebuilder:validation:Optional
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// (String) The associated storage account.
	// The associated storage account.
	// +kubebuilder:validation:Optional
	StorageAccount *string `json:"storageAccount" tf:"storage_account,omitempty"`

	// (String) Your tenant id.
	// Your tenant id.
	// +kubebuilder:validation:Optional
	TenantID *string `json:"tenantId" tf:"tenant_id,omitempty"`
}

type GcsArchiveInitParameters struct {

	// (String) Name of your GCS bucket.
	// Name of your GCS bucket.
	Bucket *string `json:"bucket,omitempty" tf:"bucket,omitempty"`

	// (String) Your client email.
	// Your client email.
	ClientEmail *string `json:"clientEmail,omitempty" tf:"client_email,omitempty"`

	// (String) The path where the archive is stored.
	// Path where the archive is stored.
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// (String) Your project id.
	// Your project id.
	ProjectID *string `json:"projectId,omitempty" tf:"project_id,omitempty"`
}

type GcsArchiveObservation struct {

	// (String) Name of your GCS bucket.
	// Name of your GCS bucket.
	Bucket *string `json:"bucket,omitempty" tf:"bucket,omitempty"`

	// (String) Your client email.
	// Your client email.
	ClientEmail *string `json:"clientEmail,omitempty" tf:"client_email,omitempty"`

	// (String) The path where the archive is stored.
	// Path where the archive is stored.
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// (String) Your project id.
	// Your project id.
	ProjectID *string `json:"projectId,omitempty" tf:"project_id,omitempty"`
}

type GcsArchiveParameters struct {

	// (String) Name of your GCS bucket.
	// Name of your GCS bucket.
	// +kubebuilder:validation:Optional
	Bucket *string `json:"bucket" tf:"bucket,omitempty"`

	// (String) Your client email.
	// Your client email.
	// +kubebuilder:validation:Optional
	ClientEmail *string `json:"clientEmail" tf:"client_email,omitempty"`

	// (String) The path where the archive is stored.
	// Path where the archive is stored.
	// +kubebuilder:validation:Optional
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// (String) Your project id.
	// Your project id.
	// +kubebuilder:validation:Optional
	ProjectID *string `json:"projectId" tf:"project_id,omitempty"`
}

type S3ArchiveInitParameters struct {

	// (String) Your AWS account id.
	// Your AWS account id.
	AccountID *string `json:"accountId,omitempty" tf:"account_id,omitempty"`

	// (String) Name of your GCS bucket.
	// Name of your s3 bucket.
	Bucket *string `json:"bucket,omitempty" tf:"bucket,omitempty"`

	// (String) The path where the archive is stored.
	// Path where the archive is stored.
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// (String) Your AWS role name
	// Your AWS role name
	RoleName *string `json:"roleName,omitempty" tf:"role_name,omitempty"`
}

type S3ArchiveObservation struct {

	// (String) Your AWS account id.
	// Your AWS account id.
	AccountID *string `json:"accountId,omitempty" tf:"account_id,omitempty"`

	// (String) Name of your GCS bucket.
	// Name of your s3 bucket.
	Bucket *string `json:"bucket,omitempty" tf:"bucket,omitempty"`

	// (String) The path where the archive is stored.
	// Path where the archive is stored.
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// (String) Your AWS role name
	// Your AWS role name
	RoleName *string `json:"roleName,omitempty" tf:"role_name,omitempty"`
}

type S3ArchiveParameters struct {

	// (String) Your AWS account id.
	// Your AWS account id.
	// +kubebuilder:validation:Optional
	AccountID *string `json:"accountId" tf:"account_id,omitempty"`

	// (String) Name of your GCS bucket.
	// Name of your s3 bucket.
	// +kubebuilder:validation:Optional
	Bucket *string `json:"bucket" tf:"bucket,omitempty"`

	// (String) The path where the archive is stored.
	// Path where the archive is stored.
	// +kubebuilder:validation:Optional
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// (String) Your AWS role name
	// Your AWS role name
	// +kubebuilder:validation:Optional
	RoleName *string `json:"roleName" tf:"role_name,omitempty"`
}

// ArchiveSpec defines the desired state of Archive
type ArchiveSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     ArchiveParameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider ArchiveInitParameters `json:"initProvider,omitempty"`
}

// ArchiveStatus defines the observed state of Archive.
type ArchiveStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        ArchiveObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion

// Archive is the Schema for the Archives API. Provides a Datadog Logs Archive API resource, which is used to create and manage Datadog logs archives.
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,datadog}
type Archive struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.name) || (has(self.initProvider) && has(self.initProvider.name))",message="spec.forProvider.name is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.query) || (has(self.initProvider) && has(self.initProvider.query))",message="spec.forProvider.query is a required parameter"
	Spec   ArchiveSpec   `json:"spec"`
	Status ArchiveStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// ArchiveList contains a list of Archives
type ArchiveList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []Archive `json:"items"`
}

// Repository type metadata.
var (
	Archive_Kind             = "Archive"
	Archive_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: Archive_Kind}.String()
	Archive_KindAPIVersion   = Archive_Kind + "." + CRDGroupVersion.String()
	Archive_GroupVersionKind = CRDGroupVersion.WithKind(Archive_Kind)
)

func init() {
	SchemeBuilder.Register(&Archive{}, &ArchiveList{})
}
